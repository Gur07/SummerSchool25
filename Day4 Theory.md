# ðŸš€ Day 4: Object Detection â€” Lecture Notes

This session introduces **Object Detection** â€” going beyond "what is in the image" to also answer **"where it is"**.

---

## ðŸ“Œ Why Object Detection?

Traditional CNNs tell **what** is in an image, but not **where**.

**Goal of Object Detection:**  
Predict both the **class** and the **location (bounding box)** of each object.

---

## ðŸ” Task Variants

| Task Type                  | Description                                |
|---------------------------|--------------------------------------------|
| Classification            | Predict the object class                   |
| Classification + Localization | Predict class + single object position  |
| Object Detection           | Predict multiple objects and their positions |
| Instance Segmentation      | Detect + segment individual object pixels  |

---

## ðŸ“¦ Bounding Boxes (BBs)

Bounding boxes are rectangles around objects.

### âœ… Formats:

| Format Name     | Coordinates             | Used In       |
|-----------------|-------------------------|----------------|
| VOC             | `x_min, y_min, x_max, y_max` | Pascal VOC |
| COCO            | `x_min, y_min, width, height` | COCO       |
| YOLO            | `x_center, y_center, width, height` | YOLO  |
| Albumentations  | Flexible format         | Augmentation tool |

### ðŸ“Œ OpenCV Example:
```python
cv2.rectangle(img, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)
ðŸ“ Evaluating Bounding Boxes
Ground Truth vs Predicted Boxes
Use IoU (Intersection over Union):

ð¼
ð‘œ
ð‘ˆ
=
(
ð´
ð‘Ÿ
ð‘’
ð‘Ž
ð‘œ
ð‘“
ð‘‚
ð‘£
ð‘’
ð‘Ÿ
ð‘™
ð‘Ž
ð‘
)
/
(
ð´
ð‘Ÿ
ð‘’
ð‘Ž
ð‘œ
ð‘“
ð‘ˆ
ð‘›
ð‘–
ð‘œ
ð‘›
)
IoU=(AreaofOverlap)/(AreaofUnion)
IoU Value	Interpretation
~1	Excellent prediction
~0	Poor prediction

ðŸ§® Localization Losses
To make predictions match ground truth, we use loss functions:

Loss Type	Description	Issue
L1 Loss (MAE)	Mean Absolute Error	Ignores IoU; non-smooth near 0
L2 Loss (MSE)	Mean Squared Error	Over-penalizes large errors
Huber Loss	Combines L1 and L2	Stable training

ðŸ” IoU-Based Loss Functions
Directly optimizing IoU improves object localization.

Loss Name	Idea	Description / Use Case
IoU Loss	1 - IoU	Penalizes poor overlap
GIoU	Generalized IoU	Penalizes non-overlapping boxes
DIoU	Distance IoU	Considers center distance
CIoU	Complete IoU	Adds aspect ratio, distance, and IoU â€” used in YOLOv5/v7

âš™ï¸ Detection Pipelines
Two-Stage Detectors:
Example: Faster R-CNN

Flow: Region proposal â†’ Classification + Localization

One-Stage Detectors:
Example: YOLO, SSD

Flow: Direct prediction from image

ðŸ§® Grid-Based Prediction
In YOLO-style models:

Image is split into grid cells (e.g., 4Ã—4 = 16)

Each grid cell predicts:

x, y, w, h â†’ bounding box

confidence

class probabilities

Example:

yaml
Copy
Edit
Grid Size: 4Ã—4  
Each Cell: 7 values â†’ [x, y, w, h, conf, class1, class2]  
Total Output Tensor Shape: 4Ã—4Ã—7
âŒ Non-Maximum Suppression (NMS)
When multiple overlapping boxes are predicted:

Select box with highest confidence

Suppress boxes with high IoU overlap (> threshold)

NMS helps reduce redundant predictions.

ðŸ“Š Evaluation Metrics
Metric	Description
mAP@0.5	mean Average Precision @ IoU = 0.5
mAP@0.5:0.95	Averaged over IoU thresholds [0.5, 0.95]
Precision	Correct detections / All detections
Recall	Correct detections / All true objects
